[
  {
    "objectID": "slides/week3.html#acknowledgment",
    "href": "slides/week3.html#acknowledgment",
    "title": "Exploratory Data Analysis",
    "section": "Acknowledgment",
    "text": "Acknowledgment\nThese slides were originally developed by Meredith Franklin. They have been modified by George G. Vega Yon and Kelly Street."
  },
  {
    "objectID": "slides/week3.html#exploratory-data-analysis",
    "href": "slides/week3.html#exploratory-data-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nExploratory data analysis is the process of becoming familiar with a dataset\nIt should be the first step in your analysis pipeline\nIt involves:\n\nchecking data (import issues, outliers, missing values, data errors)\ncleaning data\nsummary statistics of key variables (univariate and bivariate)\nbasic plots and graphs"
  },
  {
    "objectID": "slides/week3.html#exploratory-data-analysis-1",
    "href": "slides/week3.html#exploratory-data-analysis-1",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nSince our eyes and brains are not wired to detect patterns in large data tables filled with text and numbers, communication about data […] rarely comes in the form of raw data or code output. Instead, data and data-driven results are usually either summarized (e.g., using an average/mean) and presented in small summary tables or they are presented visually in the form of graphs, in which shape, distance, color, and size can be used to represent the magnitudes of (and relationships between) the values within our data.\n\n\nViridical Data Science, Yu and Barter"
  },
  {
    "objectID": "slides/week3.html#the-tidyverse-model",
    "href": "slides/week3.html#the-tidyverse-model",
    "title": "Exploratory Data Analysis",
    "section": "The Tidyverse Model",
    "text": "The Tidyverse Model\n\nLoosely, EDA encompasses the Import -&gt; Tidy -&gt; Transform -&gt; Visualize steps. Basically it is everything before we do modeling, prediction or inference.\nEDA may involve some statistical summaries, but it does not include formal statistical analysis."
  },
  {
    "objectID": "slides/week3.html#eda-checklist",
    "href": "slides/week3.html#eda-checklist",
    "title": "Exploratory Data Analysis",
    "section": "EDA Checklist",
    "text": "EDA Checklist\nThe goal of EDA is to better understand your data. Let’s use the checklist:\n\nRead in the data\nCheck the size of the data\nExamine the variables and their types\nLook at the top and bottom of the data\nCheck your expectations\nValidate with an external source\nFormulate a (simple) question\nTry the easy solution first\nChallenge your solution\n\n(adapted from Exploratory Data Analysis with R by Roger D. Peng)"
  },
  {
    "objectID": "slides/week3.html#case-study",
    "href": "slides/week3.html#case-study",
    "title": "Exploratory Data Analysis",
    "section": "Case study",
    "text": "Case study\nWe are going to use a dataset created from the National Center for Environmental Information (https://www.ncei.noaa.gov/). The data are 2019 hourly measurements from weather stations across the continental U.S."
  },
  {
    "objectID": "slides/week3.html#formulate-a-question",
    "href": "slides/week3.html#formulate-a-question",
    "title": "Exploratory Data Analysis",
    "section": "Formulate a Question",
    "text": "Formulate a Question\nIt is a good idea to first have a question such as:\n\nWhich weather stations reported the hottest and coldest daily temperatures?\nWhat day of the month was on average the hottest?\nIs there correlation between temperature and humidity in my dataset?"
  },
  {
    "objectID": "slides/week3.html#read-in-the-data",
    "href": "slides/week3.html#read-in-the-data",
    "title": "Exploratory Data Analysis",
    "section": "Read in the Data",
    "text": "Read in the Data\nThere are several ways to read in data (some depend on the type of data you have):\n\nread.table or read.csv in base R for delimited files\nreadRDS if you have a .rds dataset (this is a handy, compressed way of saving R objects)\nread_csv, read_csv2, read_delim, read_fwf from library(readr) that is part of the tidyverse\nreadxl() from library(readxl) for .xls and .xlsx files\nread_sas, read_spss, read_stata from library(haven)\nfread from library(data.table) for efficiently importing large datasets that are regular delimited files"
  },
  {
    "objectID": "slides/week3.html#read-in-the-data-1",
    "href": "slides/week3.html#read-in-the-data-1",
    "title": "Exploratory Data Analysis",
    "section": "Read in the Data",
    "text": "Read in the Data\nThere are plenty of ways to do these tasks, but we will focus on base R.\nSince our data is stored as a (gzipped) CSV file, we could load it into R with read.csv, but we will use the more flexible read.table. I have it stored locally, but we will see how to load it straight from GitHub in the lab.\n\nmet &lt;- read.table(file.path('..','..','data','met_all.gz'),\n                  header = TRUE, sep = ',')\n\nWe specify that the first line contains column names by setting header = TRUE and we indicate that commas are used to separate the different values (rather than tabs, spaces, etc.) by setting sep = ','."
  },
  {
    "objectID": "slides/week3.html#working-with-data.frames",
    "href": "slides/week3.html#working-with-data.frames",
    "title": "Exploratory Data Analysis",
    "section": "Working with data.frames",
    "text": "Working with data.frames\nThis gave as a data.frame object, which is a standard R format for cleaned, rectangular data. Each row represents an observation and each column represents a variable.\nAs we have seen, you can access particular parts of the data.frame by subsetting with the square brackets, [,]. For example, you can pull out the 2nd, 3rd, and 4th elements of the 1st column of our met dataset with met[2:4, 1].\nYou can also pull out specific columns by name, using the $ operator. Since the first column is called USAFID, we could access the same subset as above with met$USAFID[2:4] (notice that there is no comma here, because we have already subset down to a single variable).\nTo see the list of names for the dataset, you can use names(met) or colnames(met). To see the top few rows of the dataset, use head(met)."
  },
  {
    "objectID": "slides/week3.html#check-the-data",
    "href": "slides/week3.html#check-the-data",
    "title": "Exploratory Data Analysis",
    "section": "Check the data",
    "text": "Check the data\nWe should check the dimensions of the data set. This can be done several ways:\n\ndim(met)\n\n[1] 2377343      30\n\nnrow(met)\n\n[1] 2377343\n\nncol(met)\n\n[1] 30"
  },
  {
    "objectID": "slides/week3.html#check-the-data-1",
    "href": "slides/week3.html#check-the-data-1",
    "title": "Exploratory Data Analysis",
    "section": "Check the data",
    "text": "Check the data\n\nWe see that there are 2,377,343 records of hourly temperature in August 2019 from all of the weather stations in the US. The data set has 30 variables.\nWe should also check the top and bottom of the dataset to check for any irregularities. Use head(met) and tail(met) for this.\nNext we can take a deeper dive into the contents of the data with str()"
  },
  {
    "objectID": "slides/week3.html#check-variables",
    "href": "slides/week3.html#check-variables",
    "title": "Exploratory Data Analysis",
    "section": "Check variables",
    "text": "Check variables\n\nstr(met)\n\n'data.frame':   2377343 obs. of  30 variables:\n $ USAFID           : int  690150 690150 690150 690150 690150 690150 690150 690150 690150 690150 ...\n $ WBAN             : int  93121 93121 93121 93121 93121 93121 93121 93121 93121 93121 ...\n $ year             : int  2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 ...\n $ month            : int  8 8 8 8 8 8 8 8 8 8 ...\n $ day              : int  1 1 1 1 1 1 1 1 1 1 ...\n $ hour             : int  0 1 2 3 4 5 6 7 8 9 ...\n $ min              : int  56 56 56 56 56 56 56 56 56 56 ...\n $ lat              : num  34.3 34.3 34.3 34.3 34.3 34.3 34.3 34.3 34.3 34.3 ...\n $ lon              : num  -116 -116 -116 -116 -116 ...\n $ elev             : int  696 696 696 696 696 696 696 696 696 696 ...\n $ wind.dir         : int  220 230 230 210 120 NA 320 10 320 350 ...\n $ wind.dir.qc      : chr  \"5\" \"5\" \"5\" \"5\" ...\n $ wind.type.code   : chr  \"N\" \"N\" \"N\" \"N\" ...\n $ wind.sp          : num  5.7 8.2 6.7 5.1 2.1 0 1.5 2.1 2.6 1.5 ...\n $ wind.sp.qc       : chr  \"5\" \"5\" \"5\" \"5\" ...\n $ ceiling.ht       : int  22000 22000 22000 22000 22000 22000 22000 22000 22000 22000 ...\n $ ceiling.ht.qc    : int  5 5 5 5 5 5 5 5 5 5 ...\n $ ceiling.ht.method: chr  \"9\" \"9\" \"9\" \"9\" ...\n $ sky.cond         : chr  \"N\" \"N\" \"N\" \"N\" ...\n $ vis.dist         : int  16093 16093 16093 16093 16093 16093 16093 16093 16093 16093 ...\n $ vis.dist.qc      : chr  \"5\" \"5\" \"5\" \"5\" ...\n $ vis.var          : chr  \"N\" \"N\" \"N\" \"N\" ...\n $ vis.var.qc       : chr  \"5\" \"5\" \"5\" \"5\" ...\n $ temp             : num  37.2 35.6 34.4 33.3 32.8 31.1 29.4 28.9 27.2 26.7 ...\n $ temp.qc          : chr  \"5\" \"5\" \"5\" \"5\" ...\n $ dew.point        : num  10.6 10.6 7.2 5 5 5.6 6.1 6.7 7.8 7.8 ...\n $ dew.point.qc     : chr  \"5\" \"5\" \"5\" \"5\" ...\n $ atm.press        : num  1010 1010 1011 1012 1013 ...\n $ atm.press.qc     : int  5 5 5 5 5 5 5 5 5 5 ...\n $ rh               : num  19.9 21.8 18.5 16.9 17.4 ..."
  },
  {
    "objectID": "slides/week3.html#check-variables-1",
    "href": "slides/week3.html#check-variables-1",
    "title": "Exploratory Data Analysis",
    "section": "Check variables",
    "text": "Check variables\n\nFirst, we see that str() gives us the class of the data, which in this case is a data.frame, as well as the dimensions of the data\nWe also see the variable names and their type (integer, numeric, character, etc.)\nWe can identify major problems with the data at this stage (e.g. a variable that has all missing values)"
  },
  {
    "objectID": "slides/week3.html#check-variables-2",
    "href": "slides/week3.html#check-variables-2",
    "title": "Exploratory Data Analysis",
    "section": "Check variables",
    "text": "Check variables\nWe can get summary statistics on our data.frame using summary().\n\nsummary(met[,8:13])\n\n      lat             lon               elev           wind.dir     \n Min.   :24.55   Min.   :-124.29   Min.   : -13.0   Min.   :  3     \n 1st Qu.:33.97   1st Qu.: -98.02   1st Qu.: 101.0   1st Qu.:120     \n Median :38.35   Median : -91.71   Median : 252.0   Median :180     \n Mean   :37.94   Mean   : -92.15   Mean   : 415.8   Mean   :185     \n 3rd Qu.:41.94   3rd Qu.: -82.99   3rd Qu.: 400.0   3rd Qu.:260     \n Max.   :48.94   Max.   : -68.31   Max.   :9999.0   Max.   :360     \n                                                    NA's   :785290  \n wind.dir.qc        wind.type.code    \n Length:2377343     Length:2377343    \n Class :character   Class :character  \n Mode  :character   Mode  :character"
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely",
    "href": "slides/week3.html#check-variables-more-closely",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nWe know that we are supposed to have hourly measurements of weather data for the month of August 2019 for the entire US. We should check that we have all of these components. Let’s check:\n\nthe year\nthe month\nthe hours\nthe range of locations (latitude and longitude)"
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely-1",
    "href": "slides/week3.html#check-variables-more-closely-1",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nWe can generate tables and/or barplots for integer variables:\n\ntable(met$hour)\n\n\n     0      1      2      3      4      5      6      7      8      9     10 \n 99434  93482  93770  96703 110504 112128 106235 101985 100310 102915 101880 \n    11     12     13     14     15     16     17     18     19     20     21 \n100470 103605  97004  96507  97635  94942  94184 100179  94604  94928  96070 \n    22     23 \n 94046  93823 \n\ntable(met$month)\n\n\n      8 \n2377343"
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely-2",
    "href": "slides/week3.html#check-variables-more-closely-2",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nWe can generate tables and/or barplots for integer variables:\n\nbarplot(table(met$hour))"
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely-3",
    "href": "slides/week3.html#check-variables-more-closely-3",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nFor numeric variables we should do a summary to see the quantiles, min, max, and mean.\n\ntable(met$year)\n\n\n   2019 \n2377343 \n\nsummary(met$lat)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.55   33.97   38.35   37.94   41.94   48.94 \n\nsummary(met$lon)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-124.29  -98.02  -91.71  -92.15  -82.99  -68.31"
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely-4",
    "href": "slides/week3.html#check-variables-more-closely-4",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nWe can visualize these distributions with a histogram.\n\nlayout(matrix(1:2, nrow=1))\nhist(met$lat)\nhist(met$lon)\n\n\n\n\n\n\n\nlayout(1)"
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely-5",
    "href": "slides/week3.html#check-variables-more-closely-5",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nIf we return to our initial question, what weather stations reported the hottest and coldest temperatures, we should take a closer look at our key variable, temperature (temp)\n\nsummary(met$temp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n -40.00   19.60   23.50   23.59   27.80   56.00   60089 \n\nhist(met$temp)\n\n\nIt looks like the temperatures are in Celsius. A temperature of -40 in August is really cold, we should see if this is an implausible value."
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely-6",
    "href": "slides/week3.html#check-variables-more-closely-6",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nIt also looks like there is a lot of missing data, encoded by NA values. Let’s check the proportion of missingness by tallying up whether or not every temperature reading is an NA. This will give us a vector of TRUE/FALSE values and then we can take the mean (average), because R automatically interprets TRUE as 1 and FALSE as 0 for mathematical functions.\n\nmean(is.na(met$temp))\n\n[1] 0.0252757\n\n\n2.5% of the data are missing, which is not a huge amount."
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely-7",
    "href": "slides/week3.html#check-variables-more-closely-7",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nIn our data.frame we can easily subset the data and select certain columns. Here, we select all observations with a temperature of -40C and a specific subset of the variables:\n\nmet_ss &lt;- met[met$temp == -40.00, c('hour','lat','lon','elev','wind.sp')]\n\ndim(met_ss)\n\n[1] 60125     5\n\nsummary(met_ss)\n\n      hour            lat             lon              elev      \n Min.   : 0.00   Min.   :29.12   Min.   :-89.55   Min.   :36     \n 1st Qu.: 2.75   1st Qu.:29.12   1st Qu.:-89.55   1st Qu.:36     \n Median : 5.50   Median :29.12   Median :-89.55   Median :36     \n Mean   : 5.50   Mean   :29.12   Mean   :-89.55   Mean   :36     \n 3rd Qu.: 8.25   3rd Qu.:29.12   3rd Qu.:-89.55   3rd Qu.:36     \n Max.   :11.00   Max.   :29.12   Max.   :-89.55   Max.   :36     \n NA's   :60089   NA's   :60089   NA's   :60089    NA's   :60089  \n    wind.sp     \n Min.   : NA    \n 1st Qu.: NA    \n Median : NA    \n Mean   :NaN    \n 3rd Qu.: NA    \n Max.   : NA    \n NA's   :60125"
  },
  {
    "objectID": "slides/week3.html#check-variables-more-closely-8",
    "href": "slides/week3.html#check-variables-more-closely-8",
    "title": "Exploratory Data Analysis",
    "section": "Check variables more closely",
    "text": "Check variables more closely\nIn dplyr we can do the same thing using filter and select\n\nlibrary(dplyr)\nmet_ss &lt;- filter(met, temp == -40.00) |&gt; \n  select(USAFID, day, hour, lat, lon, elev, wind.sp)\n\ndim(met_ss)\n\n[1] 36  7\n\nsummary(met_ss)\n\n     USAFID            day         hour            lat             lon        \n Min.   :720717   Min.   :1   Min.   : 0.00   Min.   :29.12   Min.   :-89.55  \n 1st Qu.:720717   1st Qu.:1   1st Qu.: 2.75   1st Qu.:29.12   1st Qu.:-89.55  \n Median :720717   Median :1   Median : 5.50   Median :29.12   Median :-89.55  \n Mean   :720717   Mean   :1   Mean   : 5.50   Mean   :29.12   Mean   :-89.55  \n 3rd Qu.:720717   3rd Qu.:1   3rd Qu.: 8.25   3rd Qu.:29.12   3rd Qu.:-89.55  \n Max.   :720717   Max.   :1   Max.   :11.00   Max.   :29.12   Max.   :-89.55  \n                                                                              \n      elev       wind.sp   \n Min.   :36   Min.   : NA  \n 1st Qu.:36   1st Qu.: NA  \n Median :36   Median : NA  \n Mean   :36   Mean   :NaN  \n 3rd Qu.:36   3rd Qu.: NA  \n Max.   :36   Max.   : NA  \n              NA's   :36"
  },
  {
    "objectID": "slides/week3.html#validate-against-an-external-source",
    "href": "slides/week3.html#validate-against-an-external-source",
    "title": "Exploratory Data Analysis",
    "section": "Validate against an external source",
    "text": "Validate against an external source\nWe should check outside sources to make sure that our data makes sense. For example the observation with -40C is suspicious, so we should look up the location of the weather station.\nGo to Google maps and enter the coordinates for the site with -40C (29.12, -89.55)\n\nIt doesn’t make much sense to have a -40C reading in the Gulf of Mexico off the coast of Louisiana!"
  },
  {
    "objectID": "slides/week3.html#data-cleaning",
    "href": "slides/week3.html#data-cleaning",
    "title": "Exploratory Data Analysis",
    "section": "Data cleaning",
    "text": "Data cleaning\nIf we return to our initial question (“Which weather stations reported the hottest and coldest daily temperatures?”), we need to generate a list of weather stations that are ordered from highest to lowest. We can then examine the top and bottom of this new dataset.\nFirst let us remove the aberrant observations and then we’ll sort by temperature.\n\nmet &lt;- met[met$temp &gt; -40, ]\n\nNotice that we do not create a new object, we just overwrite the met object. Once you’re sure that you want to remove certain observations, this is a good way to avoid confusion (otherwise, it is easy to end up with multiple subsets of the data in your R environment with similar names like met, met_ss, met_ss2, met_final, met_FINAL, met_FINAL_REAL, etc.)"
  },
  {
    "objectID": "slides/week3.html#data-cleaning-1",
    "href": "slides/week3.html#data-cleaning-1",
    "title": "Exploratory Data Analysis",
    "section": "Data cleaning",
    "text": "Data cleaning\nWe will also remove any observations with missing temperature values (NA).\nThe is.na() function tells you whether or not a particular value is missing and the ! operator takes the opposite of a TRUE/FALSE value, so in combination, they tell you which observations are not missing.\n\nmet &lt;- met[!is.na(met$temp), ]"
  },
  {
    "objectID": "slides/week3.html#highest-and-lowest",
    "href": "slides/week3.html#highest-and-lowest",
    "title": "Exploratory Data Analysis",
    "section": "Highest and Lowest",
    "text": "Highest and Lowest\n\nhead(met)[,c(1,8:10,24)]\n\n        USAFID    lat    lon elev  temp\n1203053 722817 38.767 -104.3 1838 -17.2\n1203055 722817 38.767 -104.3 1838 -17.2\n1203128 722817 38.767 -104.3 1838 -17.2\n1203129 722817 38.767 -104.3 1838 -17.2\n1203222 722817 38.767 -104.3 1838 -17.2\n1203225 722817 38.767 -104.3 1838 -17.2\n\ntail(met)[,c(1,8:10,24)]\n\n      USAFID    lat      lon elev temp\n42783 720267 38.955 -121.081  467 52.0\n724   690150 34.300 -116.166  696 52.8\n749   690150 34.296 -116.162  625 52.8\n748   690150 34.300 -116.166  696 53.9\n701   690150 34.300 -116.166  696 54.4\n42403 720267 38.955 -121.081  467 56.0"
  },
  {
    "objectID": "slides/week3.html#summary-statistics",
    "href": "slides/week3.html#summary-statistics",
    "title": "Exploratory Data Analysis",
    "section": "Summary statistics",
    "text": "Summary statistics\nThe maximum hourly temperature is 56C at site 720267, and the minimum hourly temperature is -17.2C at site 722817."
  },
  {
    "objectID": "slides/week3.html#summary-statistics-1",
    "href": "slides/week3.html#summary-statistics-1",
    "title": "Exploratory Data Analysis",
    "section": "Summary statistics",
    "text": "Summary statistics\nWe need to transform our data to answer our initial question. Let’s find the daily mean, max, and min temperatures for each weather station in our data.frame. We can do this with the summarize function from the dplyr package. This package is part of the tidyverse, so the syntax is a bit different from what we’ve seen before.\n\nlibrary(dplyr)\nmet_daily &lt;- summarize(met,\n                       temp = mean(temp),\n                       lat = mean(lat),\n                       lon = mean(lon),\n                       elev = mean(elev),\n                       .by = c(USAFID, day))\n\nWhat we’ve done here is told R to summarize the met dataset by the variables USAFID and day, splitting the data into subsets based on those two indexing variables. For each subset (representing a specific station of a specific day), we want the daily average temperature, as well as latitude, longitude, and elevation (though hopefully those don’t change too much over the course of a day!)"
  },
  {
    "objectID": "slides/week3.html#summary-statistics-2",
    "href": "slides/week3.html#summary-statistics-2",
    "title": "Exploratory Data Analysis",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nBefore we continue, check the relative sizes of the met and met_daily objects. Which one is bigger?"
  },
  {
    "objectID": "slides/week3.html#summary-statistics-3",
    "href": "slides/week3.html#summary-statistics-3",
    "title": "Exploratory Data Analysis",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nNow we will order our new dataset by the average daily temperature, just as we ordered the old one by observed temperature.\n\nmet_daily &lt;- met_daily[order(met_daily$temp), ]\n\nhead(met_daily)\n\n    USAFID day       temp    lat    lon elev\n2   722817   3 -17.200000 38.767 -104.3 1838\n1   722817   1 -17.133333 38.767 -104.3 1838\n3   722817   6 -17.066667 38.767 -104.3 1838\n164 726130  11   4.278261 44.270  -71.3 1909\n166 726130  31   4.304348 44.270  -71.3 1909\n163 726130  10   4.583333 44.270  -71.3 1909\n\ntail(met_daily)\n\n      USAFID day     temp      lat       lon     elev\n48708 722749   5 40.85714 33.26900 -111.8120 379.0000\n48695 723805   5 40.97500 34.76800 -114.6180 279.0000\n48721 720339  14 41.00000 32.14600 -111.1710 737.0000\n48710 723805   4 41.18333 34.76800 -114.6180 279.0000\n48688 722787   5 41.35714 33.52700 -112.2950 325.0000\n48438 690150  31 41.71667 34.29967 -116.1657 690.0833"
  },
  {
    "objectID": "slides/week3.html#summary-statistics-4",
    "href": "slides/week3.html#summary-statistics-4",
    "title": "Exploratory Data Analysis",
    "section": "Summary statistics",
    "text": "Summary statistics\nThe maximum daily average temperature is 41.7166667 C at site 690150 and the minimum daily average temperature is -17.2C at site 722817."
  },
  {
    "objectID": "slides/week3.html#summary-statistics-5",
    "href": "slides/week3.html#summary-statistics-5",
    "title": "Exploratory Data Analysis",
    "section": "Summary statistics",
    "text": "Summary statistics\nThe code below is similar to our previous example, but doesn’t include the latitude, longitude, and elevation. How would you alter this code to find the daily median, max, or min temperatures for each station?\n\nsummarize(met,\n          temp = mean(temp),\n          .by = c(USAFID, day))\n\n(try it yourself)"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs",
    "href": "slides/week3.html#exploratory-graphs",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory graphs",
    "text": "Exploratory graphs\nWith exploratory graphs we aim to:\n\ndebug any issues remaining in the data\nunderstand properties of the data\nlook for patterns in the data\ninform modeling strategies\n\nExploratory graphs do not need to be perfect, we will look at presentation ready plots next week."
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-1",
    "href": "slides/week3.html#exploratory-graphs-1",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory graphs",
    "text": "Exploratory graphs\nExamples of exploratory graphs include:\n\nhistograms\nboxplots\nscatterplots\nsimple maps"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-2",
    "href": "slides/week3.html#exploratory-graphs-2",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nFocusing on the variable of interest, temperature, let’s look at the distribution (after removing -40C)\n\nhist(met$temp)"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-3",
    "href": "slides/week3.html#exploratory-graphs-3",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nLet’s look at the daily data\n\nhist(met_daily$temp)"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-4",
    "href": "slides/week3.html#exploratory-graphs-4",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nA boxplot gives us an idea of the quantiles of the distribution and any outliers\n\nboxplot(met$temp, col = \"blue\")"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-5",
    "href": "slides/week3.html#exploratory-graphs-5",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nLet’s look at the daily data\n\nboxplot(met_daily$temp, col = \"blue\")"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-6",
    "href": "slides/week3.html#exploratory-graphs-6",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nWe know that these data come from US weather stations, so we might have some idea what to expect just from plotting the latitude and longitude (note that we fix the aspect ratio at 1:1 with asp = 1; this prevents the plot from stretching or shrinking to fit the available plotting area):\n\nplot(met_daily$lon, met_daily$lat, asp=1)"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-7",
    "href": "slides/week3.html#exploratory-graphs-7",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nA map will show us where the weather stations are located. First let’s get the unique latitudes and longitudes and see how many meteorological sites there are\n\nmet_stations &lt;- (unique(met[,c(\"lat\",\"lon\")]))  \ndim(met_stations)\n\n[1] 2827    2"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-8",
    "href": "slides/week3.html#exploratory-graphs-8",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nA map will show us where the weather stations are located. First let’s get the unique latitudes and longitudes and see how many meteorological sites there are.\n\nlibrary(leaflet)\nleaflet(met_stations) |&gt; \n  addProviderTiles('CartoDB.Positron') |&gt; \n  addCircles(lat = ~lat, lng = ~lon,\n             opacity = 1, fillOpacity = 1, radius = 400)"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-9",
    "href": "slides/week3.html#exploratory-graphs-9",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-10",
    "href": "slides/week3.html#exploratory-graphs-10",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nLet’s map the locations of the max and min daily temperatures.\n\nmin &lt;- met_daily[1, ]               # First observation\nmax &lt;- met_daily[nrow(met_daily), ] # Last observation\n\nleaflet() |&gt; \n  addProviderTiles('CartoDB.Positron') |&gt; \n  addCircles(\n    data = min,\n    lat = ~lat, lng = ~lon, popup = \"Min temp.\",\n    opacity = 1, fillOpacity = 1, radius = 400, color = \"blue\"\n    ) |&gt;\n  addCircles(\n    data = max,\n    lat = ~lat, lng = ~lon, popup = \"Max temp.\",\n    opacity=1, fillOpacity=1, radius = 400, color = \"red\"\n    )\n\n(next slide)"
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-11",
    "href": "slides/week3.html#exploratory-graphs-11",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nScatterplots help us look at pairwise relationships. Let’s see if there is any trend in temperature with latitude\n\nplot(met_daily$lat, met_daily$temp, pch=16, cex=0.5)\n\n\n\n\n\n\n\n\nThere is a clear decrease in temperatures as you increase in latitude (i.e as you go north)."
  },
  {
    "objectID": "slides/week3.html#exploratory-graphs-12",
    "href": "slides/week3.html#exploratory-graphs-12",
    "title": "Exploratory Data Analysis",
    "section": "Exploratory Graphs",
    "text": "Exploratory Graphs\nWe can add a simple linear regression line to this plot using lm() and abline(). We can also add a title and change the axis labels.\n\nmod &lt;- lm(temp ~ lat, data = met_daily)\nmet_daily[, plot(\n  lat, temp, pch=19, cex=0.5, \n  main = \"Temperature and Latitude\", \n  xlab = \"Latitude\", ylab = \"Temperature (deg C)\")\n  ]\nabline(mod, lwd=2, col=\"red\")\n\n(next slide)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to PHDS",
    "section": "",
    "text": "Term: Fall 2024\nTime: Friday 9am - 12:55pm\nLocation: SSB 114\nGitHub"
  },
  {
    "objectID": "index.html#pm-566-introduction-to-health-data-science",
    "href": "index.html#pm-566-introduction-to-health-data-science",
    "title": "Intro to PHDS",
    "section": "",
    "text": "Term: Fall 2024\nTime: Friday 9am - 12:55pm\nLocation: SSB 114\nGitHub"
  },
  {
    "objectID": "slides/week4.html#acknowledgment",
    "href": "slides/week4.html#acknowledgment",
    "title": "Data Visualization",
    "section": "Acknowledgment",
    "text": "Acknowledgment\nThese slides were originally developed by Meredith Franklin (and Paul Marjoram) and modified by George G. Vega Yon."
  },
  {
    "objectID": "slides/week4.html#background",
    "href": "slides/week4.html#background",
    "title": "Data Visualization",
    "section": "Background",
    "text": "Background\n\nThis lecture provides an introduction to ggplot2, an R package that provides vastly better graphics options than R’s default plots, histograms, etc.\nThis section is based on chapter 3 of “R for Data Science”"
  },
  {
    "objectID": "slides/week4.html#background-1",
    "href": "slides/week4.html#background-1",
    "title": "Data Visualization",
    "section": "Background",
    "text": "Background\nggplot2 is part of the Tidyverse. The tidyverse is…“an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” (https://www.tidyverse.org/)\n\nlibrary(tidyverse)\nlibrary(data.table)"
  },
  {
    "objectID": "slides/week4.html#ggplot2",
    "href": "slides/week4.html#ggplot2",
    "title": "Data Visualization",
    "section": "ggplot2",
    "text": "ggplot2\nggplot2 is designed on the principle of adding layers."
  },
  {
    "objectID": "slides/week4.html#ggplot2-1",
    "href": "slides/week4.html#ggplot2-1",
    "title": "Data Visualization",
    "section": "ggplot2",
    "text": "ggplot2\n\nWith ggplot2 a plot is initiated with the function ggplot()\nThe first argument of ggplot() is the dataset to use in the graph\nLayers are added to ggplot() with +\nLayers include geom functions such as point, lines, etc\nEach geom function takes a mapping argument, which is always paired with aes()\nThe aes() mapping takes the x and y axes of the plot\n\n\nggplot(data = data) +\n    geom_function(mapping = aes(mappings))"
  },
  {
    "objectID": "slides/week4.html#data",
    "href": "slides/week4.html#data",
    "title": "Data Visualization",
    "section": "Data",
    "text": "Data\nContinuing with the weather data from last week, let’s take the daily averages at each site, keeping some of the variables. Let’s also create a new variable for region (east and west), categorize elevation, and create a multi-category variable for visibility for exploratory purposes.\n\n# Reading the data, filtering, and replacing NAs\nmet &lt;- fread(file.path('..','..','data','met_all.gz'))\nmet &lt;- met[met$temp &gt; -10][elev == 9999.0, elev := NA]\n\n# Creating an aggregated version of the dataset\nmet_avg &lt;- met[,.(\n  temp     = mean(temp,na.rm=TRUE),\n  rh       = mean(rh,na.rm=TRUE),\n  wind.sp  = mean(wind.sp,na.rm=TRUE),\n  vis.dist = mean(vis.dist,na.rm=TRUE),\n  lat      = mean(lat),\n  lon      = mean(lon), \n  elev     = mean(elev,na.rm=TRUE)\n), by=c(\"USAFID\", \"day\")]"
  },
  {
    "objectID": "slides/week4.html#basic-scatterplot",
    "href": "slides/week4.html#basic-scatterplot",
    "title": "Data Visualization",
    "section": "Basic Scatterplot",
    "text": "Basic Scatterplot\n\nplot(met_avg$temp, met_avg$rh)"
  },
  {
    "objectID": "slides/week4.html#basic-scatterplot-1",
    "href": "slides/week4.html#basic-scatterplot-1",
    "title": "Data Visualization",
    "section": "Basic Scatterplot",
    "text": "Basic Scatterplot\nHere’s how to create a basic plot in ggplot2\n\nggplot(data = met_avg) + \n  geom_point(mapping = aes(x = temp, y = rh))\n\n\nWe see that as temperature increases, relative humidity decreases."
  },
  {
    "objectID": "slides/week4.html#basic-scatterplot-2",
    "href": "slides/week4.html#basic-scatterplot-2",
    "title": "Data Visualization",
    "section": "Basic Scatterplot 2",
    "text": "Basic Scatterplot 2\n\ngeom_point() adds a layer of points to your plot, to create a scatterplot.\nggplot2 comes with many geom functions that each add a different type of layer to a plot.\nEach geom function in ggplot2 takes a mapping argument. This defines how variables in your dataset are mapped to visual properties.\nThe mapping argument is always paired with aes(), and the x and y arguments of aes() specify which variables to map to the x and y axes. ggplot2 looks for the mapped variables in the data argument, in this case, met_avg\nOne common problem when creating ggplot2 graphics is to put the + in the wrong place: it has to come at the end of the line, not the start."
  },
  {
    "objectID": "slides/week4.html#coloring-by-a-variable---using-aesthetics",
    "href": "slides/week4.html#coloring-by-a-variable---using-aesthetics",
    "title": "Data Visualization",
    "section": "Coloring by a variable - using aesthetics",
    "text": "Coloring by a variable - using aesthetics\nYou can map the colors of your points to the class variable to reveal the region of data (west or east). ggplot2 chooses colors, and adds a legend, automatically.\n\nggplot(data = met_avg) + \n  geom_point(mapping = aes(x = temp, y = rh, color = region))\n\n\n\n\n\n\n\n\nWe see that humidity in the east is generally higher than in the west and that the hottest temperatures are in the west."
  },
  {
    "objectID": "slides/week4.html#controlling-point-transparency-using-the-alpha-aesthetic",
    "href": "slides/week4.html#controlling-point-transparency-using-the-alpha-aesthetic",
    "title": "Data Visualization",
    "section": "Controlling point transparency using the “alpha” aesthetic",
    "text": "Controlling point transparency using the “alpha” aesthetic\n\nggplot(data = met_avg) + \n  geom_point(mapping = aes(x = temp, y = rh, alpha = 0.3))"
  },
  {
    "objectID": "slides/week4.html#controlling-point-transparency-using-the-alpha-aesthetic-1",
    "href": "slides/week4.html#controlling-point-transparency-using-the-alpha-aesthetic-1",
    "title": "Data Visualization",
    "section": "Controlling point transparency using the “alpha” aesthetic",
    "text": "Controlling point transparency using the “alpha” aesthetic\n\nggplot(data = met_avg) + \n  geom_point(mapping = aes(x = temp, y = rh, alpha = rh))"
  },
  {
    "objectID": "slides/week4.html#controlling-point-shape",
    "href": "slides/week4.html#controlling-point-shape",
    "title": "Data Visualization",
    "section": "Controlling point shape:",
    "text": "Controlling point shape:\n\nggplot(data = met_avg) + \n  geom_point(mapping = aes(x = temp, y = rh, shape = region))\n\n\nNote that, by default, ggplot uses up to 6 shapes. If there are more, some of your data is not plotted!! (At least it warns you.)"
  },
  {
    "objectID": "slides/week4.html#summary-of-aesthetics",
    "href": "slides/week4.html#summary-of-aesthetics",
    "title": "Data Visualization",
    "section": "Summary of aesthetics",
    "text": "Summary of aesthetics\n\n\n\ncode\ndescription\n\n\n\n\nx\nposition on x-axis\n\n\ny\nposition on y-axis\n\n\nshape\nshape\n\n\ncolor\ncolor of element borders\n\n\nfill\ncolor inside of elements\n\n\nsize\nsize\n\n\nalpha\ntransparency\n\n\nlinetype\ntype of line"
  },
  {
    "objectID": "slides/week4.html#base-plot-equivalents",
    "href": "slides/week4.html#base-plot-equivalents",
    "title": "Data Visualization",
    "section": "Base plot equivalents",
    "text": "Base plot equivalents\n\n\n\ncode\ndescription\n\n\n\n\nfirst arg / x\nposition on x-axis\n\n\nsecond arg / y\nposition on y-axis\n\n\npch\nshape\n\n\ncol\ncolor of element borders\n\n\nfill\ncolor inside of elements\n\n\ncex\nsize\n\n\nscales::alpha\ntransparency\n\n\nlty\ntype of line"
  },
  {
    "objectID": "slides/week4.html#add-points-to-plot",
    "href": "slides/week4.html#add-points-to-plot",
    "title": "Data Visualization",
    "section": "Add points to plot",
    "text": "Add points to plot\nWith base plot, you can add points to an existing plot with points(), which takes the same arguments as plot() for plotting points.\n\nplot(1:10, pch = 16)\npoints(10:1, pch = 16, col = 2)"
  },
  {
    "objectID": "slides/week4.html#facets-1",
    "href": "slides/week4.html#facets-1",
    "title": "Data Visualization",
    "section": "Facets 1",
    "text": "Facets 1\nFacets are particularly useful for categorical variables.\n\nmet_avg[!is.na(region)] %&gt;% \n  ggplot() + \n  geom_point(mapping = aes(x = temp, y = rh, color=region)) + \n  facet_wrap(~ region, nrow = 1)"
  },
  {
    "objectID": "slides/week4.html#facets-2",
    "href": "slides/week4.html#facets-2",
    "title": "Data Visualization",
    "section": "Facets 2",
    "text": "Facets 2\nOr you can facet on two variables…\n\nmet_avg[!is.na(region) & !is.na(elev_cat)] %&gt;% \n  ggplot() + \n  geom_point(mapping = aes(x = temp, y = rh)) + \n  facet_grid(region ~ elev_cat)"
  },
  {
    "objectID": "slides/week4.html#facets-3",
    "href": "slides/week4.html#facets-3",
    "title": "Data Visualization",
    "section": "Facets 3",
    "text": "Facets 3\nBase plot is not good at this! You can make multiple plots within a single plotting window by utilizing the layout() function, but you will still have to make each plot manually.\n\nlayout(matrix(1:2, nrow=1))\nplot(met_avg$temp[which(met_avg$region == 'east')], met_avg$rh[which(met_avg$region == 'east')], pch = 16, col = 2)\nplot(met_avg$temp[which(met_avg$region == 'west')], met_avg$rh[which(met_avg$region == 'west')], pch = 16, col = 4)"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-1",
    "href": "slides/week4.html#geometric-objects-1",
    "title": "Data Visualization",
    "section": "Geometric objects 1",
    "text": "Geometric objects 1\nGeometric objects are used to control the type of plot you draw. So far we have used scatterplots (via geom_point). But now let’s try plotting a smoothed line fitted to the data (and note how we do side-by-side plots)\n\nlibrary(cowplot)\n\nscatterplot &lt;- ggplot(data = met_avg) + geom_point(mapping = aes(x = temp, y = rh))\nlineplot    &lt;- ggplot(data = met_avg) + geom_smooth(mapping = aes(x = temp, y = rh))\n\nplot_grid(scatterplot, lineplot, labels = \"AUTO\")"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-1-1",
    "href": "slides/week4.html#geometric-objects-1-1",
    "title": "Data Visualization",
    "section": "Geometric objects 1",
    "text": "Geometric objects 1\ncowplot is a package due to Claus Wilke, it “… is a simple add-on to ggplot. It provides various features that help with creating publication-quality figures, such as a set of themes, functions to align plots and arrange them into complex compound figures, and functions that make it easy to annotate plots and or mix plots with images.”"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-2",
    "href": "slides/week4.html#geometric-objects-2",
    "title": "Data Visualization",
    "section": "Geometric objects 2",
    "text": "Geometric objects 2\nNote that not every aesthetic works with every geom function. But now there are some new ones we can use.\n\nggplot(data = met_avg) + \n  geom_smooth(mapping = aes(x = temp, y = rh, linetype = region))\n\n\nHere we make the line type depend on the region and we clearly see east has higher rh than west, but generally as temperatures increase rh decreases in both regions."
  },
  {
    "objectID": "slides/week4.html#geometric-objects-3",
    "href": "slides/week4.html#geometric-objects-3",
    "title": "Data Visualization",
    "section": "Geometric objects 3",
    "text": "Geometric objects 3\nHistograms\n\nhist(met_avg$temp)"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-3-1",
    "href": "slides/week4.html#geometric-objects-3-1",
    "title": "Data Visualization",
    "section": "Geometric objects 3",
    "text": "Geometric objects 3\nHistograms\n\nggplot(met_avg) + \n  geom_histogram(mapping = aes(x = temp))"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-4",
    "href": "slides/week4.html#geometric-objects-4",
    "title": "Data Visualization",
    "section": "Geometric objects 4",
    "text": "Geometric objects 4\nBoxplots\n\nboxplot(met_avg$temp ~ met_avg$elev_cat)"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-4-1",
    "href": "slides/week4.html#geometric-objects-4-1",
    "title": "Data Visualization",
    "section": "Geometric objects 4",
    "text": "Geometric objects 4\nBoxplots\n\nmet_avg[!is.na(elev_cat)] %&gt;% \n  ggplot()+\n  geom_boxplot(mapping=aes(x=elev_cat, y=temp, fill=elev_cat))"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-5",
    "href": "slides/week4.html#geometric-objects-5",
    "title": "Data Visualization",
    "section": "Geometric objects 5",
    "text": "Geometric objects 5\nLineplots\n\nplot(met_avg$day[met_avg$elev==4113], met_avg$temp[met_avg$elev==4113], type = 'l')"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-5-1",
    "href": "slides/week4.html#geometric-objects-5-1",
    "title": "Data Visualization",
    "section": "Geometric objects 5",
    "text": "Geometric objects 5\nJust as you can add points to an existing plot, you can also add lines()\n\nplot(1:10, pch = 16)\nlines(10:1, col = 2, lwd = 3) # add a thick red line"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-5-2",
    "href": "slides/week4.html#geometric-objects-5-2",
    "title": "Data Visualization",
    "section": "Geometric objects 5",
    "text": "Geometric objects 5\nLineplots\n\nggplot(data = met_avg[elev==4113])+\n geom_line(mapping=aes(x=day, y=temp))"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-5-3",
    "href": "slides/week4.html#geometric-objects-5-3",
    "title": "Data Visualization",
    "section": "Geometric objects 5",
    "text": "Geometric objects 5\nPolygons\n\nworld_map &lt;- map_data(\"world\")\nggplot(data = world_map, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"darkgray\", colour = \"white\")"
  },
  {
    "objectID": "slides/week4.html#geometric-objects-5-4",
    "href": "slides/week4.html#geometric-objects-5-4",
    "title": "Data Visualization",
    "section": "Geometric objects 5",
    "text": "Geometric objects 5\nPolygons\n\nus_map &lt;- map_data(\"state\")\nggplot(data = us_map, aes(x = long, y = lat, fill = region)) +\n  geom_polygon(colour = \"white\")"
  },
  {
    "objectID": "slides/week4.html#geoms---reference",
    "href": "slides/week4.html#geoms---reference",
    "title": "Data Visualization",
    "section": "Geoms - reference",
    "text": "Geoms - reference\nggplot2 provides over 40 geoms, and extension packages provide even more (see https://ggplot2.tidyverse.org/reference/ for a sampling).\nThe best way to get a comprehensive overview is the ggplot2 cheatsheet, which you can find at https://github.com/rstudio/cheatsheets/blob/main/data-visualization-2.1.pdf"
  },
  {
    "objectID": "slides/week4.html#multiple-geoms-1",
    "href": "slides/week4.html#multiple-geoms-1",
    "title": "Data Visualization",
    "section": "Multiple geoms 1",
    "text": "Multiple geoms 1\nLet’s layer geoms\n\nmet_avg[!is.na(region)] %&gt;%\n  ggplot() + \n  geom_point(mapping = aes(x = temp, y = rh, color = region))+\n  geom_smooth(mapping = aes(x = temp, y = rh, linetype = region))"
  },
  {
    "objectID": "slides/week4.html#multiple-geoms-2",
    "href": "slides/week4.html#multiple-geoms-2",
    "title": "Data Visualization",
    "section": "Multiple geoms 2",
    "text": "Multiple geoms 2\nWe can avoid repetition of aesthetics by passing a set of mappings to ggplot(). ggplot2 will treat these mappings as global mappings that apply to each geom in the graph.\n\nmet_avg[!is.na(region)] %&gt;%\n  ggplot(mapping = aes(x = temp, y = rh, color=region, linetype=region)) +\n  geom_point() + \n  geom_smooth()"
  },
  {
    "objectID": "slides/week4.html#multiple-geoms-2-1",
    "href": "slides/week4.html#multiple-geoms-2-1",
    "title": "Data Visualization",
    "section": "Multiple geoms 2",
    "text": "Multiple geoms 2\ngeom_smooth() has options. For example if we want a linear regression line we add method=lm\n\nmet_avg[!is.na(region)] %&gt;%\n  ggplot(mapping = aes(x = temp, y = rh, color = region, linetype = region)) +\n  geom_point() + \n  geom_smooth(method = lm, se = FALSE, col = \"black\")"
  },
  {
    "objectID": "slides/week4.html#multiple-geoms-3",
    "href": "slides/week4.html#multiple-geoms-3",
    "title": "Data Visualization",
    "section": "Multiple geoms 3",
    "text": "Multiple geoms 3\nIf you place mappings in a geom function, ggplot2 will use these mappings to extend or overwrite the global mappings for that layer only. This makes it possible to display different aesthetics in different layers.\n\nmet_avg[!is.na(region)] %&gt;%\n  ggplot(mapping = aes(x = temp, y = rh)) + \n  geom_point(mapping = aes(color = region)) + \n  geom_smooth()"
  },
  {
    "objectID": "slides/week4.html#multiple-geoms-4",
    "href": "slides/week4.html#multiple-geoms-4",
    "title": "Data Visualization",
    "section": "Multiple geoms 4",
    "text": "Multiple geoms 4\nYou can use the same idea to specify different data for each layer. Here, our smooth line displays the full met dataset but the points are colored by visibilty.\n\nmet_avg[!is.na(vis_cat)] %&gt;%\n  ggplot(mapping = aes(x = temp, y = rh, alpha = 0.5)) + \n  geom_point(mapping = aes(color = vis_cat)) + \n  geom_smooth(se = FALSE)"
  },
  {
    "objectID": "slides/week4.html#statistical-transformations---another-example",
    "href": "slides/week4.html#statistical-transformations---another-example",
    "title": "Data Visualization",
    "section": "Statistical transformations - another example",
    "text": "Statistical transformations - another example\nYou might want to draw greater attention to the statistical transformation in your code. For example, you might use stat_summary(), which summarises the y values for each unique x value, to draw attention to the summary that you’re computing:\n\nl &lt;- met_avg[!is.na(vis_cat) & vis_cat != \"clear\"] %&gt;%\n  ggplot() + \n    stat_summary(mapping = aes(x = vis_cat, y = temp),\n    fun.min = min,\n    fun.max = max,\n    fun = median)"
  },
  {
    "objectID": "slides/week4.html#statistical-transformations---another-example-1",
    "href": "slides/week4.html#statistical-transformations---another-example-1",
    "title": "Data Visualization",
    "section": "Statistical transformations - another example",
    "text": "Statistical transformations - another example\n\nl"
  },
  {
    "objectID": "slides/week4.html#position-adjustments",
    "href": "slides/week4.html#position-adjustments",
    "title": "Data Visualization",
    "section": "Position adjustments",
    "text": "Position adjustments\nAn option that can be very useful is position = \"jitter\". This adds a small amount of random noise to each point. This spreads out points that might otherwise be overlapping.\n\nnojitter &lt;- ggplot(data = met_avg[1:1000,]) + \n  geom_point(mapping = aes(x = vis_cat, y = temp))\n\njitter &lt;- ggplot(data = met_avg[1:1000,]) + \n  geom_point(mapping = aes(x = vis_cat, y = temp), position = \"jitter\")"
  },
  {
    "objectID": "slides/week4.html#position-adjustments-1",
    "href": "slides/week4.html#position-adjustments-1",
    "title": "Data Visualization",
    "section": "Position adjustments",
    "text": "Position adjustments\nAn option that can be very useful is position = \"jitter\". This adds a small amount of random noise to each point. This spreads out points that might otherwise be overlapping.\n\nnojitter &lt;- ggplot(data = met_avg[1:1000,]) + \n  geom_point(mapping = aes(x = vis_cat, y = temp))\n\njitter &lt;- ggplot(data = met_avg[1:1000,]) + \n  geom_point(mapping = aes(x = vis_cat, y = temp), position = \"jitter\")"
  },
  {
    "objectID": "slides/week4.html#position-adjustments-2",
    "href": "slides/week4.html#position-adjustments-2",
    "title": "Data Visualization",
    "section": "Position adjustments",
    "text": "Position adjustments\n\nplot_grid(nojitter, jitter, labels = \"AUTO\")"
  },
  {
    "objectID": "slides/week4.html#coordinate-systems",
    "href": "slides/week4.html#coordinate-systems",
    "title": "Data Visualization",
    "section": "Coordinate systems",
    "text": "Coordinate systems\nCoordinate systems are one of the more complicated corners of ggplot. To start with something simple, here’s how to flip axes:\n\nunflipped &lt;- ggplot(data = met_avg) + \n  geom_boxplot(mapping = aes(x = vis_cat, y = temp))\n\nflipped &lt;- ggplot(data = met_avg) + \n  geom_boxplot(mapping = aes(x = vis_cat, y = temp)) +\n  coord_flip()"
  },
  {
    "objectID": "slides/week4.html#coordinate-systems-1",
    "href": "slides/week4.html#coordinate-systems-1",
    "title": "Data Visualization",
    "section": "Coordinate systems",
    "text": "Coordinate systems\n\nplot_grid(unflipped, flipped, labels = \"AUTO\")"
  },
  {
    "objectID": "slides/week4.html#coordinate-systems-2",
    "href": "slides/week4.html#coordinate-systems-2",
    "title": "Data Visualization",
    "section": "Coordinate systems",
    "text": "Coordinate systems\nThere is also the ability to control the aspect ratio using coord_quickmap() and to use polar coordinates with coord_polar().\n\nbar &lt;- ggplot(data = met_avg) + \n  geom_bar(mapping = aes(x = elev_cat, fill = elev_cat), show.legend = FALSE, width = 1) + \n  theme(aspect.ratio = 1) +\n  labs(x = NULL, y = NULL)"
  },
  {
    "objectID": "slides/week4.html#coordinate-systems-3",
    "href": "slides/week4.html#coordinate-systems-3",
    "title": "Data Visualization",
    "section": "Coordinate systems",
    "text": "Coordinate systems\n\nbar + coord_flip()\n\n\n\n\n\n\n\nbar + coord_polar()"
  },
  {
    "objectID": "slides/week4.html#modifying-labels",
    "href": "slides/week4.html#modifying-labels",
    "title": "Data Visualization",
    "section": "Modifying labels",
    "text": "Modifying labels\n\nggplot(met_avg[!is.na(region)]) +\n  geom_point(aes(temp, rh, color = region)) + \n  labs(title = \"Weather Station Data\") + \n  labs(x = expression(\"Temperature\" *~ degree * C), y = \"Relative Humidity\")"
  },
  {
    "objectID": "slides/week4.html#changing-the-theme",
    "href": "slides/week4.html#changing-the-theme",
    "title": "Data Visualization",
    "section": "Changing the Theme",
    "text": "Changing the Theme\n\nggplot(met_avg[!is.na(region)]) +\n  geom_point(aes(temp, rh, color = region)) + \n  labs(title = \"Weather Station Data\") + \n  labs(x = expression(\"Temperature\"*~degree*C), y = \"Relative Humidity\")+\n  theme_bw(base_family = \"Times\")"
  },
  {
    "objectID": "slides/week4.html#changing-the-legend",
    "href": "slides/week4.html#changing-the-legend",
    "title": "Data Visualization",
    "section": "Changing the Legend",
    "text": "Changing the Legend\n\nggplot(met_avg[!is.na(region)]) +\n  geom_point(aes(temp, rh, color = region)) + \n  labs(title = \"Weather Station Data\",x = expression(\"Temperature\"*~degree*C), y = \"Relative Humidity\")+\n  scale_color_manual(name=\"Region\", labels=c(\"East\", \"West\"), values=c(\"east\"=\"lightblue\", \"west\"=\"purple\"))+\n  theme_bw(base_family = \"Times\")"
  },
  {
    "objectID": "slides/week4.html#changing-colorscales",
    "href": "slides/week4.html#changing-colorscales",
    "title": "Data Visualization",
    "section": "Changing Colorscales",
    "text": "Changing Colorscales\n\nggplot(data = met_avg) + \n  geom_point(mapping=aes(x=temp, y=rh, color=elev))+\n  scale_color_gradient(low=\"blue\", high=\"red\")"
  },
  {
    "objectID": "slides/week4.html#changing-colorscales-1",
    "href": "slides/week4.html#changing-colorscales-1",
    "title": "Data Visualization",
    "section": "Changing Colorscales",
    "text": "Changing Colorscales\n\nggplot(data=met_avg) + \n  geom_point(mapping= aes(x=temp, y=rh, color = cut(elev, b=5))) + \n  scale_color_manual(values = viridis::viridis(6))"
  },
  {
    "objectID": "slides/week4.html#a-great-reference",
    "href": "slides/week4.html#a-great-reference",
    "title": "Data Visualization",
    "section": "A Great reference",
    "text": "A Great reference\nA great (comprehensive) reference for everything you can do with ggplot2 is the R Graphics Cookbook:\nhttps://r-graphics.org/"
  },
  {
    "objectID": "slides/week4.html#reminder---the-ggplot2-cheatsheet",
    "href": "slides/week4.html#reminder---the-ggplot2-cheatsheet",
    "title": "Data Visualization",
    "section": "Reminder - the ggplot2 cheatsheet",
    "text": "Reminder - the ggplot2 cheatsheet\nA briefer summary can be found here:\nhttps://github.com/rstudio/cheatsheets/blob/main/data-visualization-2.1.pdf\nRstudio has a variety of other great Cheatsheets."
  },
  {
    "objectID": "slides/week4.html#maps-with-leaflet",
    "href": "slides/week4.html#maps-with-leaflet",
    "title": "Data Visualization",
    "section": "Maps with leaflet",
    "text": "Maps with leaflet\nLet’s create a map of monthly average temperatures at each of the weather stations and colour the points by a temperature gradient. We need to create a colour palette and we can add a legend.\n\nlibrary(leaflet)\nmet_avg2 &lt;- met[,.(temp = mean(temp,na.rm=TRUE), lat = mean(lat), lon = mean(lon)),  by=c(\"USAFID\")]\nmet_avg2 &lt;- met_avg2[!is.na(temp)]\n\n# Generating a color palette\ntemp.pal &lt;- colorNumeric(c('darkgreen','goldenrod','brown'), domain=met_avg2$temp)\ntemp.pal\n\nfunction (x) \n{\n    if (length(x) == 0 || all(is.na(x))) {\n        return(pf(x))\n    }\n    if (is.null(rng)) \n        rng &lt;- range(x, na.rm = TRUE)\n    rescaled &lt;- scales::rescale(x, from = rng)\n    if (any(rescaled &lt; 0 | rescaled &gt; 1, na.rm = TRUE)) \n        warning(\"Some values were outside the color scale and will be treated as NA\")\n    if (reverse) {\n        rescaled &lt;- 1 - rescaled\n    }\n    pf(rescaled)\n}\n&lt;bytecode: 0x7f9fddf233b8&gt;\n&lt;environment: 0x7f9fddf257a8&gt;\nattr(,\"colorType\")\n[1] \"numeric\"\nattr(,\"colorArgs\")\nattr(,\"colorArgs\")$na.color\n[1] \"#808080\""
  },
  {
    "objectID": "slides/week4.html#maps-with-leaflet-1",
    "href": "slides/week4.html#maps-with-leaflet-1",
    "title": "Data Visualization",
    "section": "Maps with leaflet",
    "text": "Maps with leaflet\nFor the tile providers, take a look at this site: https://leaflet-extras.github.io/leaflet-providers/preview/\n\ntempmap &lt;- leaflet(met_avg2) %&gt;% \n  # The looks of the Map\n  addProviderTiles('CartoDB.Positron') %&gt;% \n  # Some circles\n  addCircles(\n    lat = ~lat, lng=~lon,\n                                                  # HERE IS OUR PAL!\n    label = ~paste0(round(temp,2), ' C'), color = ~ temp.pal(temp),\n    opacity = 1, fillOpacity = 1, radius = 500\n    ) %&gt;%\n  # And a pretty legend\n  addLegend('bottomleft', pal=temp.pal, values=met_avg2$temp,\n          title='Temperature, C', opacity=1)"
  },
  {
    "objectID": "slides/week4.html#maps-with-leaflet-2",
    "href": "slides/week4.html#maps-with-leaflet-2",
    "title": "Data Visualization",
    "section": "Maps with leaflet",
    "text": "Maps with leaflet\n\ntempmap"
  }
]